{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c78a10f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_18064\\1893272904.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_data[\"current_date\"] = date.today()\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_18064\\1893272904.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_data[\"asset_addition_date\"] = date.today()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import heapq\n",
    "from datetime import date\n",
    "import quantstats as qs \n",
    "\n",
    "def calculate_average_returns(folder_path):\n",
    "    # Dictionary to store average returns for each ETF\n",
    "    average_returns_dict = {}\n",
    "\n",
    "    # Iterate over each file in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Convert 'Date' column to datetime format\n",
    "            df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
    "\n",
    "            # Calculate the average returns for 1, 3, 6, 9, and 12 months\n",
    "            average_returns = {}\n",
    "            for months in [1, 3, 6, 9, 12]:\n",
    "                end_date = df['Date'].max()\n",
    "                start_date = end_date - pd.DateOffset(months=months)\n",
    "                filtered_data = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]\n",
    "                returns = (filtered_data['Close'].iloc[-1] - filtered_data['Close'].iloc[0]) / filtered_data['Close'].iloc[0]\n",
    "                average_returns[f'{months}_month'] = returns / months\n",
    "\n",
    "            # Store the average returns in the dictionary with the ETF name\n",
    "            average_returns_dict[filename.split('.')[0]] = average_returns\n",
    "\n",
    "    return average_returns_dict\n",
    "\n",
    "def calculate_overall_average_returns(average_returns_dict):\n",
    "    # Dictionary to store overall average returns for each ETF\n",
    "    overall_average_returns = {}\n",
    "\n",
    "    # Iterate over each ETF\n",
    "    for etf, returns_dict in average_returns_dict.items():\n",
    "        # Calculate the overall average for the ETF\n",
    "        overall_average = sum(returns_dict.values()) / len(returns_dict)\n",
    "        overall_average_returns[etf] = overall_average\n",
    "\n",
    "    return overall_average_returns\n",
    "\n",
    "folder_path = r\"C:\\Users\\DELL\\Desktop\\Projects\\Codeshastra X\\Data\\Sectoral ETF\"\n",
    "average_returns = calculate_average_returns(folder_path)\n",
    "overall_average_returns = calculate_overall_average_returns(average_returns)\n",
    "top_three_etfs = heapq.nlargest(3, overall_average_returns, key=overall_average_returns.get)\n",
    "\n",
    "def prepare_data_frame(top_three_etfs, folder_path):\n",
    "    df_list = []\n",
    "    for etf in top_three_etfs:\n",
    "        df = pd.read_csv(folder_path + f\"\\\\{etf}.csv\")\n",
    "        df[\"asset_name\"] = etf\n",
    "        df[\"asset_category\"] = \"ETF\"\n",
    "        df.rename(\n",
    "            columns={\n",
    "                \"Open\": \"open_price\",\n",
    "                \"High\": \"high_price\",\n",
    "                \"Low\": \"low_price\",\n",
    "                \"Close\": \"close_price\",\n",
    "                \"Volume\": \"volume\",\n",
    "                \"Date\": \"current_date\"\n",
    "            },\n",
    "            inplace=True\n",
    "        )\n",
    "        df[\"current_date\"] = pd.to_datetime(df['current_date'], format=\"%Y-%m-%d\")\n",
    "        df = df[df[\"current_date\"] >= df[\"current_date\"].max() - pd.DateOffset(years=1)]\n",
    "        df.drop([\"volume\", \"Adj Close\"], axis=1, inplace=True)\n",
    "        df_list.append(df)\n",
    "        \n",
    "    # Concatenate data frames without resetting index\n",
    "    all_data = pd.concat(df_list, ignore_index=True)\n",
    "    all_data[\"current_date\"] = pd.to_datetime(all_data['current_date'], format=\"%Y-%m-%d\")\n",
    "    all_data.set_index(\"current_date\", inplace=True)\n",
    "    \n",
    "    all_data[\"percentage_1_d_cagr\"] = qs.stats.cagr(all_data[\"close_price\"].resample(\"1D\").last())\n",
    "    all_data[\"percentage_3_m_cagr\"] = qs.stats.cagr(all_data[\"close_price\"].resample(\"3M\").last())\n",
    "    all_data[\"percentage_1_y_cagr\"] = qs.stats.cagr(all_data[\"close_price\"].resample(\"1Y\").last())\n",
    "    all_data[\"percentage_3_m_volatility\"] = qs.stats.volatility(all_data[\"close_price\"].resample(\"3M\").last())\n",
    "    all_data[\"percentage_1_y_volatility\"] = qs.stats.volatility(all_data[\"close_price\"].resample(\"1Y\").last())\n",
    "    \n",
    "    # Calculate ratios\n",
    "    grouped_data = all_data.groupby(\"asset_name\")\n",
    "\n",
    "    all_data[\"ratio_sharpe\"] = all_data[\"asset_name\"].map(grouped_data.apply(lambda x: qs.stats.sharpe(x[\"close_price\"])))\n",
    "    all_data[\"ratio_sortino\"] = all_data[\"asset_name\"].map(grouped_data.apply(lambda x: qs.stats.sortino(x[\"close_price\"])))\n",
    "    all_data[\"ratio_win_loss\"] = all_data[\"asset_name\"].map(grouped_data.apply(lambda x: qs.stats.win_loss_ratio(x[\"close_price\"])))\n",
    "    all_data[\"percentage_drawdown\"] = all_data[\"asset_name\"].map(grouped_data.apply(lambda x: qs.stats.max_drawdown(x[\"close_price\"])))\n",
    "    all_data = all_data[all_data.index == all_data.index.max()]    \n",
    "    \n",
    "    all_data[\"current_date\"] = date.today()\n",
    "    all_data[\"asset_addition_date\"] = date.today()\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "all_data = prepare_data_frame(top_three_etfs, folder_path)\n",
    "\n",
    "def check_spy_moving_average(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df.set_index('Date', inplace=True)\n",
    "    \n",
    "    # Calculate the 10-month moving average\n",
    "    moving_avg_10m = df['Close'].rolling(window=10).mean()\n",
    "    \n",
    "    # Get the latest close price and the latest 10-month moving average\n",
    "    latest_close_price = df['Close'].iloc[-1]\n",
    "    latest_10m_avg = moving_avg_10m.iloc[-1]\n",
    "    \n",
    "    # Check if the latest close price is lesser than the 10-month moving average\n",
    "    if latest_close_price < latest_10m_avg:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "all_cash = check_spy_moving_average(r\"C:\\Users\\DELL\\Desktop\\Projects\\Codeshastra X\\Data\\Broad Indices\\SPY.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b94c7a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_18064\\661070523.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_data[\"current_date\"] = date.today()\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_18064\\661070523.py:110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_data[\"asset_addition_date\"] = date.today()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_price</th>\n",
       "      <th>high_price</th>\n",
       "      <th>low_price</th>\n",
       "      <th>close_price</th>\n",
       "      <th>asset_name</th>\n",
       "      <th>asset_category</th>\n",
       "      <th>percentage_1_d_cagr</th>\n",
       "      <th>percentage_3_m_cagr</th>\n",
       "      <th>percentage_1_y_cagr</th>\n",
       "      <th>percentage_3_m_volatility</th>\n",
       "      <th>percentage_1_y_volatility</th>\n",
       "      <th>ratio_sharpe</th>\n",
       "      <th>ratio_sortino</th>\n",
       "      <th>ratio_win_loss</th>\n",
       "      <th>percentage_drawdown</th>\n",
       "      <th>current_date</th>\n",
       "      <th>asset_addition_date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-03-28</th>\n",
       "      <td>111.160004</td>\n",
       "      <td>111.959999</td>\n",
       "      <td>110.680000</td>\n",
       "      <td>111.589996</td>\n",
       "      <td>XHB</td>\n",
       "      <td>ETF</td>\n",
       "      <td>0.298644</td>\n",
       "      <td>0.266067</td>\n",
       "      <td>0.083722</td>\n",
       "      <td>1.000855</td>\n",
       "      <td>1.390376</td>\n",
       "      <td>2.454664</td>\n",
       "      <td>3.927108</td>\n",
       "      <td>1.076583</td>\n",
       "      <td>-0.184192</td>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>2024-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-28</th>\n",
       "      <td>41.939999</td>\n",
       "      <td>42.220001</td>\n",
       "      <td>41.869999</td>\n",
       "      <td>42.119999</td>\n",
       "      <td>XLF</td>\n",
       "      <td>ETF</td>\n",
       "      <td>0.298644</td>\n",
       "      <td>0.266067</td>\n",
       "      <td>0.083722</td>\n",
       "      <td>1.000855</td>\n",
       "      <td>1.390376</td>\n",
       "      <td>2.337618</td>\n",
       "      <td>3.664184</td>\n",
       "      <td>1.144534</td>\n",
       "      <td>-0.116573</td>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>2024-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-28</th>\n",
       "      <td>81.769997</td>\n",
       "      <td>81.900002</td>\n",
       "      <td>81.510002</td>\n",
       "      <td>81.660004</td>\n",
       "      <td>XLC</td>\n",
       "      <td>ETF</td>\n",
       "      <td>0.298644</td>\n",
       "      <td>0.266067</td>\n",
       "      <td>0.083722</td>\n",
       "      <td>1.000855</td>\n",
       "      <td>1.390376</td>\n",
       "      <td>2.305760</td>\n",
       "      <td>3.819320</td>\n",
       "      <td>1.277495</td>\n",
       "      <td>-0.083127</td>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>2024-03-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              open_price  high_price   low_price  close_price asset_name  \\\n",
       "current_date                                                               \n",
       "2024-03-28    111.160004  111.959999  110.680000   111.589996        XHB   \n",
       "2024-03-28     41.939999   42.220001   41.869999    42.119999        XLF   \n",
       "2024-03-28     81.769997   81.900002   81.510002    81.660004        XLC   \n",
       "\n",
       "             asset_category  percentage_1_d_cagr  percentage_3_m_cagr  \\\n",
       "current_date                                                            \n",
       "2024-03-28              ETF             0.298644             0.266067   \n",
       "2024-03-28              ETF             0.298644             0.266067   \n",
       "2024-03-28              ETF             0.298644             0.266067   \n",
       "\n",
       "              percentage_1_y_cagr  percentage_3_m_volatility  \\\n",
       "current_date                                                   \n",
       "2024-03-28               0.083722                   1.000855   \n",
       "2024-03-28               0.083722                   1.000855   \n",
       "2024-03-28               0.083722                   1.000855   \n",
       "\n",
       "              percentage_1_y_volatility  ratio_sharpe  ratio_sortino  \\\n",
       "current_date                                                           \n",
       "2024-03-28                     1.390376      2.454664       3.927108   \n",
       "2024-03-28                     1.390376      2.337618       3.664184   \n",
       "2024-03-28                     1.390376      2.305760       3.819320   \n",
       "\n",
       "              ratio_win_loss  percentage_drawdown current_date  \\\n",
       "current_date                                                     \n",
       "2024-03-28          1.076583            -0.184192   2024-03-31   \n",
       "2024-03-28          1.144534            -0.116573   2024-03-31   \n",
       "2024-03-28          1.277495            -0.083127   2024-03-31   \n",
       "\n",
       "             asset_addition_date  \n",
       "current_date                      \n",
       "2024-03-28            2024-03-31  \n",
       "2024-03-28            2024-03-31  \n",
       "2024-03-28            2024-03-31  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import heapq\n",
    "from datetime import datetime, timedelta, date\n",
    "import quantstats as qs\n",
    "\n",
    "def calculate_average_returns(folder_path):\n",
    "    \"\"\"\n",
    "    Calculate the average returns for ETFs in the given folder path.\n",
    "\n",
    "    Args:\n",
    "    folder_path (str): Path to the folder containing ETF data files.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary containing average returns for each ETF.\n",
    "    \"\"\"\n",
    "    average_returns_dict = {}  # Dictionary to store average returns for each ETF\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
    "\n",
    "            average_returns = {}\n",
    "            for months in [1, 3, 6, 9, 12]:\n",
    "                end_date = df['Date'].max()\n",
    "                start_date = end_date - pd.DateOffset(months=months)\n",
    "                filtered_data = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]\n",
    "                returns = (filtered_data['Close'].iloc[-1] - filtered_data['Close'].iloc[0]) / filtered_data['Close'].iloc[0]\n",
    "                average_returns[f'{months}_month'] = returns / months\n",
    "\n",
    "            average_returns_dict[filename.split('.')[0]] = average_returns\n",
    "\n",
    "    return average_returns_dict\n",
    "\n",
    "def calculate_overall_average_returns(average_returns_dict):\n",
    "    \"\"\"\n",
    "    Calculate the overall average returns for each ETF.\n",
    "\n",
    "    Args:\n",
    "    average_returns_dict (dict): Dictionary containing average returns for each ETF.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary containing overall average returns for each ETF.\n",
    "    \"\"\"\n",
    "    overall_average_returns = {}\n",
    "\n",
    "    for etf, returns_dict in average_returns_dict.items():\n",
    "        overall_average = sum(returns_dict.values()) / len(returns_dict)\n",
    "        overall_average_returns[etf] = overall_average\n",
    "\n",
    "    return overall_average_returns\n",
    "\n",
    "def prepare_data_frame(top_three_etfs, folder_path):\n",
    "    \"\"\"\n",
    "    Prepare a DataFrame containing data for the top three ETFs.\n",
    "\n",
    "    Args:\n",
    "    top_three_etfs (list): List of top three ETFs.\n",
    "    folder_path (str): Path to the folder containing ETF data files.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame containing data for the top three ETFs.\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    for etf in top_three_etfs:\n",
    "        df = pd.read_csv(os.path.join(folder_path, f\"{etf}.csv\"))\n",
    "        df[\"asset_name\"] = etf\n",
    "        df[\"asset_category\"] = \"ETF\"\n",
    "        df.rename(\n",
    "            columns={\n",
    "                \"Open\": \"open_price\",\n",
    "                \"High\": \"high_price\",\n",
    "                \"Low\": \"low_price\",\n",
    "                \"Close\": \"close_price\",\n",
    "                \"Volume\": \"volume\",\n",
    "                \"Date\": \"current_date\"\n",
    "            },\n",
    "            inplace=True\n",
    "        )\n",
    "        df[\"current_date\"] = pd.to_datetime(df['current_date'], format=\"%Y-%m-%d\")\n",
    "        df = df[df[\"current_date\"] >= df[\"current_date\"].max() - pd.DateOffset(years=1)]\n",
    "        df.drop([\"volume\", \"Adj Close\"], axis=1, inplace=True)\n",
    "        df_list.append(df)\n",
    "\n",
    "    all_data = pd.concat(df_list, ignore_index=True)\n",
    "    all_data.set_index(\"current_date\", inplace=True)\n",
    "\n",
    "    # Calculate various statistics\n",
    "    all_data[\"percentage_1_d_cagr\"] = qs.stats.cagr(all_data[\"close_price\"].resample(\"1D\").last())\n",
    "    all_data[\"percentage_3_m_cagr\"] = qs.stats.cagr(all_data[\"close_price\"].resample(\"3M\").last())\n",
    "    all_data[\"percentage_1_y_cagr\"] = qs.stats.cagr(all_data[\"close_price\"].resample(\"1Y\").last())\n",
    "    all_data[\"percentage_3_m_volatility\"] = qs.stats.volatility(all_data[\"close_price\"].resample(\"3M\").last())\n",
    "    all_data[\"percentage_1_y_volatility\"] = qs.stats.volatility(all_data[\"close_price\"].resample(\"1Y\").last())\n",
    "\n",
    "    grouped_data = all_data.groupby(\"asset_name\")\n",
    "    all_data[\"ratio_sharpe\"] = all_data[\"asset_name\"].map(grouped_data.apply(lambda x: qs.stats.sharpe(x[\"close_price\"])))\n",
    "    all_data[\"ratio_sortino\"] = all_data[\"asset_name\"].map(grouped_data.apply(lambda x: qs.stats.sortino(x[\"close_price\"])))\n",
    "    all_data[\"ratio_win_loss\"] = all_data[\"asset_name\"].map(grouped_data.apply(lambda x: qs.stats.win_loss_ratio(x[\"close_price\"])))\n",
    "    all_data[\"percentage_drawdown\"] = all_data[\"asset_name\"].map(grouped_data.apply(lambda x: qs.stats.max_drawdown(x[\"close_price\"])))\n",
    "    all_data = all_data[all_data.index == all_data.index.max()]    \n",
    "\n",
    "    all_data[\"current_date\"] = date.today()\n",
    "    all_data[\"asset_addition_date\"] = date.today()\n",
    "\n",
    "    return all_data\n",
    "\n",
    "def check_spy_moving_average(file_path):\n",
    "    \"\"\"\n",
    "    Check if the latest close price of SPY is below its 10-month moving average.\n",
    "\n",
    "    Args:\n",
    "    file_path (str): Path to the SPY data file.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the latest close price is below the 10-month moving average, False otherwise.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df.set_index('Date', inplace=True)\n",
    "\n",
    "    moving_avg_10m = df['Close'].rolling(window=10).mean()\n",
    "    latest_close_price = df['Close'].iloc[-1]\n",
    "    latest_10m_avg = moving_avg_10m.iloc[-1]\n",
    "\n",
    "    return latest_close_price < latest_10m_avg\n",
    "\n",
    "folder_path = r\"C:\\Users\\DELL\\Desktop\\Projects\\Codeshastra X\\Data\\Sectoral ETF\"\n",
    "spy_file_path = r\"C:\\Users\\DELL\\Desktop\\Projects\\Codeshastra X\\Data\\Broad Indices\\SPY.csv\"\n",
    "\n",
    "average_returns = calculate_average_returns(folder_path)\n",
    "overall_average_returns = calculate_overall_average_returns(average_returns)\n",
    "top_three_etfs = heapq.nlargest(3, overall_average_returns, key=overall_average_returns.get)\n",
    "\n",
    "all_data = prepare_data_frame(top_three_etfs, folder_path)\n",
    "all_cash = check_spy_moving_average(spy_file_path)\n",
    "\n",
    "# Print or use 'all_cash' and 'all_data' as required\n",
    "all_cash\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e498833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import os\n",
    "import pandas as pd\n",
    "import heapq\n",
    "from datetime import datetime, timedelta, date\n",
    "import quantstats as qs\n",
    "import pyodbc\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# SQL Server connection parameters\n",
    "driver = \"{ODBC Driver 17 for SQL Server}\"\n",
    "server = \"localhost\\\\SQLEXPRESS\"\n",
    "database = \"your_database_name\"\n",
    "trusted_connection = \"yes\"\n",
    "\n",
    "# Construct connection string\n",
    "DB_CONNECTION_STRING = f\"DRIVER={driver};SERVER={server};DATABASE={database};TRUSTED_CONNECTION={trusted_connection};\"\n",
    "\n",
    "def connect_to_database():\n",
    "    return pyodbc.connect(DB_CONNECTION_STRING)\n",
    "\n",
    "def calculate_average_returns(folder_path):\n",
    "    \"\"\"\n",
    "    Calculate the average returns for ETFs in the given folder path.\n",
    "\n",
    "    Args:\n",
    "    folder_path (str): Path to the folder containing ETF data files.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary containing average returns for each ETF.\n",
    "    \"\"\"\n",
    "    average_returns_dict = {}  # Dictionary to store average returns for each ETF\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
    "\n",
    "            average_returns = {}\n",
    "            for months in [1, 3, 6, 9, 12]:\n",
    "                end_date = df['Date'].max()\n",
    "                start_date = end_date - pd.DateOffset(months=months)\n",
    "                filtered_data = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]\n",
    "                returns = (filtered_data['Close'].iloc[-1] - filtered_data['Close'].iloc[0]) / filtered_data['Close'].iloc[0]\n",
    "                average_returns[f'{months}_month'] = returns / months\n",
    "\n",
    "            average_returns_dict[filename.split('.')[0]] = average_returns\n",
    "\n",
    "    return average_returns_dict\n",
    "\n",
    "def calculate_overall_average_returns(average_returns_dict):\n",
    "    \"\"\"\n",
    "    Calculate the overall average returns for each ETF.\n",
    "\n",
    "    Args:\n",
    "    average_returns_dict (dict): Dictionary containing average returns for each ETF.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary containing overall average returns for each ETF.\n",
    "    \"\"\"\n",
    "    overall_average_returns = {}\n",
    "\n",
    "    for etf, returns_dict in average_returns_dict.items():\n",
    "        overall_average = sum(returns_dict.values()) / len(returns_dict)\n",
    "        overall_average_returns[etf] = overall_average\n",
    "\n",
    "    return overall_average_returns\n",
    "\n",
    "def prepare_data_frame(top_three_etfs, folder_path):\n",
    "    \"\"\"\n",
    "    Prepare a DataFrame containing data for the top three ETFs.\n",
    "\n",
    "    Args:\n",
    "    top_three_etfs (list): List of top three ETFs.\n",
    "    folder_path (str): Path to the folder containing ETF data files.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame containing data for the top three ETFs.\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    for etf in top_three_etfs:\n",
    "        df = pd.read_csv(os.path.join(folder_path, f\"{etf}.csv\"))\n",
    "        df[\"asset_name\"] = etf\n",
    "        df[\"asset_category\"] = \"ETF\"\n",
    "        df.rename(\n",
    "            columns={\n",
    "                \"Open\": \"open_price\",\n",
    "                \"High\": \"high_price\",\n",
    "                \"Low\": \"low_price\",\n",
    "                \"Close\": \"close_price\",\n",
    "                \"Volume\": \"volume\",\n",
    "                \"Date\": \"current_date\"\n",
    "            },\n",
    "            inplace=True\n",
    "        )\n",
    "        df[\"current_date\"] = pd.to_datetime(df['current_date'], format=\"%Y-%m-%d\")\n",
    "        df = df[df[\"current_date\"] >= df[\"current_date\"].max() - pd.DateOffset(years=1)]\n",
    "        df.drop([\"volume\", \"Adj Close\"], axis=1, inplace=True)\n",
    "        df_list.append(df)\n",
    "\n",
    "    all_data = pd.concat(df_list, ignore_index=True)\n",
    "    all_data.set_index(\"current_date\", inplace=True)\n",
    "\n",
    "    # Calculate various statistics\n",
    "    all_data[\"percentage_1_d_cagr\"] = qs.stats.cagr(all_data[\"close_price\"].resample(\"1D\").last())\n",
    "    all_data[\"percentage_3_m_cagr\"] = qs.stats.cagr(all_data[\"close_price\"].resample(\"3M\").last())\n",
    "    all_data[\"percentage_1_y_cagr\"] = qs.stats.cagr(all_data[\"close_price\"].resample(\"1Y\").last())\n",
    "    all_data[\"percentage_3_m_volatility\"] = qs.stats.volatility(all_data[\"close_price\"].resample(\"3M\").last())\n",
    "    all_data[\"percentage_1_y_volatility\"] = qs.stats.volatility(all_data[\"close_price\"].resample(\"1Y\").last())\n",
    "\n",
    "    grouped_data = all_data.groupby(\"asset_name\")\n",
    "    all_data[\"ratio_sharpe\"] = all_data[\"asset_name\"].map(grouped_data.apply(lambda x: qs.stats.sharpe(x[\"close_price\"])))\n",
    "    all_data[\"ratio_sortino\"] = all_data[\"asset_name\"].map(grouped_data.apply(lambda x: qs.stats.sortino(x[\"close_price\"])))\n",
    "    all_data[\"ratio_win_loss\"] = all_data[\"asset_name\"].map(grouped_data.apply(lambda x: qs.stats.win_loss_ratio(x[\"close_price\"])))\n",
    "    all_data[\"percentage_drawdown\"] = all_data[\"asset_name\"].map(grouped_data.apply(lambda x: qs.stats.max_drawdown(x[\"close_price\"])))\n",
    "    all_data = all_data[all_data.index == all_data.index.max()]    \n",
    "\n",
    "    all_data[\"current_date\"] = date.today()\n",
    "    all_data[\"asset_addition_date\"] = date.today()\n",
    "\n",
    "    return all_data\n",
    "\n",
    "def check_spy_moving_average(file_path):\n",
    "    \"\"\"\n",
    "    Check if the latest close price of SPY is below its 10-month moving average.\n",
    "\n",
    "    Args:\n",
    "    file_path (str): Path to the SPY data file.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the latest close price is below the 10-month moving average, False otherwise.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df.set_index('Date', inplace=True)\n",
    "\n",
    "    moving_avg_10m = df['Close'].rolling(window=10).mean()\n",
    "    latest_close_price = df['Close'].iloc[-1]\n",
    "    latest_10m_avg = moving_avg_10m.iloc[-1]\n",
    "\n",
    "    return latest_close_price < latest_10m_avg\n",
    "\n",
    "@app.route('/portfolio', methods=['POST'])\n",
    "def portfolio():\n",
    "    portfolio_name = request.json.get('portfolio_name')\n",
    "    allocation = request.json.get('allocation')\n",
    "    \n",
    "    if not portfolio_name:\n",
    "        return jsonify({'error': 'Portfolio name is required'}), 400\n",
    "\n",
    "    folder_path = os.path.join(r\"C:\\Users\\DELL\\Desktop\\Projects\\Codeshastra X\\Data\", portfolio_name)\n",
    "    spy_file_path = r\"C:\\Users\\DELL\\Desktop\\Projects\\Codeshastra X\\Data\\Broad Indices\\SPY.csv\"\n",
    "\n",
    "    average_returns = calculate_average_returns(folder_path)\n",
    "    overall_average_returns = calculate_overall_average_returns(average_returns)\n",
    "    top_three_etfs = heapq.nlargest(3, overall_average_returns, key=overall_average_returns.get)\n",
    "\n",
    "    all_data = prepare_data_frame(top_three_etfs, folder_path)\n",
    "    all_cash = check_spy_moving_average(spy_file_path)\n",
    "    \n",
    "    if all_cash:\n",
    "        # Connect to the database\n",
    "        conn = connect_to_database()\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        try:\n",
    "            # Delete data from portfolio details table\n",
    "            cursor.execute(\"DELETE FROM portfolio_details WHERE portfolio_name = ? AND current_date = (SELECT MAX(current_date) FROM portfolio_details WHERE portfolio_name = ?)\", (portfolio_name, portfolio_name))\n",
    "\n",
    "            # Delete data from portfolio_performance table\n",
    "            cursor.execute(\"DELETE FROM portfolio_performance WHERE portfolio_name = ? AND current_date = (SELECT MAX(current_date) FROM portfolio_performance WHERE portfolio_name = ?)\", (portfolio_name, portfolio_name))\n",
    "\n",
    "            # Update percentage_cash value to 50 in latest_allocation table\n",
    "            cursor.execute(\"UPDATE latest_allocation SET percentage_allocation_cash = 50 WHERE portfolio_name = ?\", (portfolio_name,))\n",
    "            \n",
    "            # Commit the transaction\n",
    "            conn.commit()\n",
    "\n",
    "            # Close the cursor and connection\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            # If an error occurs, rollback the transaction and handle the exception\n",
    "            conn.rollback()\n",
    "            return jsonify({'error': str(e)}), 500\n",
    "\n",
    "    else:\n",
    "        if allocation > all_data['percentage_cash']:\n",
    "            pass\n",
    "        else:\n",
    "            # Directly update percentage_cash value\n",
    "            new_percentage_cash = all_data['percentage_allocation_cash'] - 3 * allocation\n",
    "            cursor.execute(\"UPDATE latest_allocation SET percentage_allocation_cash = ? WHERE portfolio_name = ?\", (new_percentage_cash, portfolio_name))\n",
    "            \n",
    "            # Directly update percentage_etf value\n",
    "            new_percentage_etf = all_data['percentage_allocation_etf'] + allocation * 3\n",
    "            cursor.execute(\"UPDATE latest_allocation SET percentage_allocation_etf = ? WHERE portfolio_name = ?\", (new_percentage_etf, portfolio_name))\n",
    "            \n",
    "            # Add all_data df to the portfolio_details table\n",
    "            all_data['percentage_allocation'] = allocation\n",
    "            all_data.to_sql('portfolio_details', conn, if_exists='append', index=False)\n",
    "            \n",
    "            \n",
    "            new_percentage_etf = all_data['percentage_allocation_etf'] + allocation * 3\n",
    "            cursor.execute(\"UPDATE portfolio_performance SET percentage_allocation_etf = ? WHERE portfolio_name = ?\", (new_percentage_etf, portfolio_name))\n",
    "               \n",
    "            # Commit the transaction\n",
    "            conn.commit()\n",
    "\n",
    "    # You can return the results as JSON\n",
    "    return jsonify({'all_cash': all_cash, 'all_data': all_data.to_dict()}), 200\n",
    "\n",
    "# Your existing functions for calculations and data preparation\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
